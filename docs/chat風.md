# VoTex Visualize — Kansai vs Tokyo Accent Demo

## 概要

このドキュメントは、**VoTex Visualize** プロジェクトのサンプルとして制作した「関西人 × 東京人の会話デモ」の解説です。音声認識後のデータ（ASR出力など）をテキストベースで可視化し、音声的特徴（感情・アクセント・音量・テンポ・ピッチ）をチャット風UIで直感的に表示するものです。

本デモでは、**「にいさん」「ありがとう」** のイントネーションをめぐる関西人（A）と東京人（B）のやりとりを題材としています。Aは関西イントネーションに強いこだわりを持ち、Bは標準語話者として戸惑い気味の設定です。

---

## 実装の構成

### 1. 表示UI（React + TailwindCSS）

* 吹き出し形式のチャット表示。

* 再生に合わせて発話中の単語が **太字＋下線** でカラオケ風にハイライトされます。

* 各単語に対して以下のパラメータをリアルタイムに反映：

  | 要素        | 表現方法                           | 対応特徴量               |
  | --------- | ------------------------------ | ------------------- |
  | **文字の色**  | Hue-Saturation-Lightness (HSL) | 感情（Valence/Arousal） |
  | **文字サイズ** | 大小                             | 音量（Loudness）        |
  | **字間**    | 詰まり/広がり                        | テンポ（Tempo）          |
  | **上下位置**  | 高低のゆれ                          | ピッチ（F0）             |

* 感情はPlutchikなどの複雑モデルではなく、**Valence（快不快）× Arousal（覚醒度）** の2次元空間で近似。

  * 暖色系：ポジティブ／高覚醒（元気・怒りなど）
  * 寒色系：ネガティブ／低覚醒（落ち込み・穏やかなど）

---

### 2. データ生成ロジック（擬似音声特徴生成）

* 各単語に対して `pitch(f0)`, `loudness`, `tempo`, `valence`, `arousal` を生成。
* 特に「関西話者（A）」の **「にいさん」「ありがとう」** に対しては：

  * ピッチ振幅（±28Hz→±40Hz）
  * 音量ブースト（+0.2）
  * 覚醒度上昇（Arousal +0.25）
  * 快不快やや低下（Valence -0.2）
    といった“訛り特有の強調”を再現。

### 3. ループ再生・インタラクション

* 再生／停止ボタン、速度変更（0.75〜1.5×）を装備。
* タイムラインスライダーで任意位置にジャンプ可能。
* 現在発話中の単語を中心に自動スクロール。

---

## シナリオ構成

| 発話 | 話者    | 概要                          |
| -- | ----- | --------------------------- |
| u1 | 関西（A） | 「それ違うって何回も言うたやろ」怒り気味に注意     |
| u2 | 東京（B） | 「え、同じつもりでした…」謝罪と戸惑い         |
| u3 | 関西（A） | 「にいさん ありがとう のここ上がるやろ！」強調と指導 |
| u4 | 東京（B） | 「もう一度 にいさん ありがとう」試みるがまだ控えめ  |
| u5 | 関西（A） | 「そうそう、それや」少し満足気             |
| u6 | 東京（B） | 「にいさん ありがとう こうですか？」改善を試す    |

---

## 技術ポイント

* **Pitchレンジ拡大**：±12px で上下ゆれを明確に。
* **感情マップ（Valence/Arousal）**：2D座標→HSL変換で色に反映。
* **フォントサイズ・字間**：RMS音量・発話速度から線形マッピング。
* **モジュール内テスト**：clamp・tempoToLS・vaToHsl の単体検証を追加。

---

## デモ利用想定

* Web上での教育・研究・展示デモ向け（音声なし・アニメーションのみ）。
* 今後は WhisperX などの ASR／F0 抽出と接続することで、実音声との連動も可能。
* Sakura Internet AppRun などの軽量コンテナ環境でデモ運用予定。

---

## 今後の拡張

1. **実音声対応**：Whisper + pyAudioAnalysis でリアル音声から特徴抽出。
2. **方言辞書統合**：テキスト辞書とTF-IDF照合による地域スコア算出。
3. **感情モデル連携**：日本語音声向けの事前学習済み感情分類器を統合。
4. **音声＋文字RAG**：方言・感情・イントネーションを説明可能にする生成応答。

---

## 実行例（Codex CLI）

```bash
codex run KaraokeChatVA.tsx
```

または Next.js/React 環境に組み込み、`<KaraokeChatVA />` コンポーネントとして使用できます。

---

**制作者メモ：**
このサンプルは「方言と言語感情の可視化」をテーマとしたVoTex Visualizeの初期実装です。
今後、地域音声コーパス（JVS, JSUT等）をベースに、より多次元的な訛り・感情表現を反映予定。
