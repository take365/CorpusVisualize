# 文＋音声特徴タグ設計概要

## 1. 概要
本ドキュメントは、「文に区切られたテキスト」と「話者識別済み音声データ」を統合し、発話の**内容的特徴**および**音声的特徴**から話者特性をタグとして自動付与するための設計方針をまとめたものである。

---

## 2. 背景
通常のASRテキストでは「誰が話したか」「どのように話したか（トーン、間、感情）」の情報が失われる。そこで、話者セグメントと音響特徴を利用して、次のようなタグを抽出し、会話構造・個性を可視化する。

### 想定データ
- Whisper等による音声認識済テキスト（文単位）
- ECAPA-TDNN等による話者ID付きセグメント
- 各セグメントの音響特徴（F0, RMS, スペクトル等）
- ターン単位の時刻情報（start / end / gap）

---

## 3. タグ付与の目的
- 話者の発話傾向・性格・役割を抽出
- 会話の構造（ターンテイキング、重なり、テンポ）を分析
- 音声可視化（ピッチ・音量・感情など）に活用
- 対話データセットのメタ情報強化

---

## 4. タグカテゴリ一覧

### A. ターンテイキング・会話運転
| タグ | 内容 | 指標例 |
|------|------|--------|
| せっかち | ターン切替が速い・かぶせ発話 | gap < 100ms, overlap > 0 |
| かぶせ癖 | 相手発話終了前に開始 | overlap率↑ |
| ターン保持 | 長発話・自己遷移多 | 平均ターン長↑ |
| 司会者 | 質問・指名語多 | 疑問率＋呼称出現率 |
| まとめ役 | 要約・再陳述多 | discourse marker:「つまり」「要するに」 |

### B. 音声的特徴
| タグ | 内容 | 指標例 |
|------|------|--------|
| 尻つぼみ | 語尾で音量減少 | ΔRMS(end)<-6dB |
| 語尾上がり | 終端でピッチ上昇 | ΔF0(end)>0 |
| クール | F0/RMS変動小 | var(F0)<閾値 |
| 熱量高め | 高音量・高ピッチ | RMS↑, F0↑ |
| フィラー多め | 「あー」「えー」など多 | filler率↑ |
| 引き笑い | 笑い＋吸気音 | ラフ成分＋周期検出 |
| モゴモゴ | 明瞭度低下 | スペクトル平坦度↑ |

### C. 言語スタイル（テキスト解析）
| タグ | 内容 | 指標例 |
|------|------|--------|
| 否定屋 | 「いや」「でも」から始まる | 文頭否定率↑ |
| アイデアマン | 新規語・仮定表現多 | 比喩・仮定率↑ |
| 皮肉屋 | ポジ×ネガ文脈 | sentiment flip |
| 結論先出し | 要点→詳細の順 | discourse構造 |
| 回りくどい | 前置き長い | 平均文長↑, 主述遅延↑ |
| 抽象志向 | 抽象名詞多 | 抽象語比↑ |
| 具体志向 | 数値・固有名詞多 | 数値・名詞率↑ |

### D. 感情・態度
| タグ | 内容 | 指標例 |
|------|------|--------|
| 自信高め | 断定語・強調多 | モダリティ強度↑ |
| 迷いがち | フィラー＋修正多 | filler率＋self-correction↑ |
| 感情安定 | 変動小 | F0分散・感情エントロピー↓ |
| 疲労 | 時間経過でRMS↓ | ΔRMS/time↓ |

### E. 方言・発音
| タグ | 内容 | 指標例 |
|------|------|--------|
| 関西訛り | 特定語＋イントネーション | 辞書＋アクセント核位置 |
| 東北訛り | 同上 | 〜だべ、〜すけど 等 |

### F. 対人行動・ポライトネス
| タグ | 内容 | 指標例 |
|------|------|--------|
| 同調型 | 相手語彙の反復 | ミラーリング率↑ |
| 反論型 | 否定接続・反対意見多 | but/しかし率↑ |
| 承認多め | 「いいですね」「助かる」多 | positive feedback率↑ |
| 提案型 | 命令・依頼文多 | imperative率↑ |

---

## 5. タグ抽出パイプライン

```mermaid
graph TD;
A[Whisper音声認識] --> B[文分割];
B --> C[話者分離(ECAPA)];
C --> D[特徴抽出(F0, RMS, 笑い, フィラー)];
D --> E[テキスト解析(形態素, 感情, 構文)];
E --> F[タグ付与(ルール/ML)];
F --> G[JSON出力 + 可視化(UI)]
```

---

## 6. 特徴量一覧
- **タイミング系**：gap, overlap, duration, speech_rate
- **音響系**：RMS_mean/std, F0_mean/std/slope_end, ZCR, flatness, laugh_prob
- **言語系**：品詞分布, 否定率, 疑問率, 比喩, 仮定, 感情スコア
- **環境系**：SNR, reverb指数, 距離変動指標

---

## 7. 出力スキーマ例
```json
{
  "turn_id": 42,
  "speaker": "A",
  "start": 123.40,
  "end": 126.90,
  "text": "あらその模試テスト良かったのかな",
  "metrics": {
    "gap_ms": -80,
    "rms_mean": -18.3,
    "f0_mean": 210.2,
    "f0_slope_end": 0.19,
    "filler_ratio": 0.03
  },
  "tags": [
    {"name": "語尾上がり", "score": 0.66},
    {"name": "司会者", "score": 0.78}
  ]
}
```

---

## 8. 可視化例
- 吹き出し単位でタグ表示（例: 尻つぼみ / 司会者 / フィラー多め）
- ひらがな単位で音量=サイズ, ピッチ=上下位置, 時間=横軸で配置
- 各ターン下に波形スパークライン表示
- ターン間ギャップ（ms）を枠間に挿入して「せっかち」「かぶせ」を視覚化

---

## 9. 今後の展望
- 機械学習によるタグ確率推定（SVM, LightGBM, transformer fine-tune）
- 感情・方言識別の精度向上
- タグ時系列のクラスタリング・人物特性推定
- 対話UI（Plotly/WaveSurfer）連携によるインタラクティブ可視化