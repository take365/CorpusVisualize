# VoTex Visualize（概要・更新版）

**VoTex Visualize** は、音声会話を多面的に可視化するインタラクティブなダッシュボードです。発話内容だけでなく「どのように話しているか」に注目し、音声的特徴とテキスト的特徴を組み合わせて、話者ごとの傾向を見える化します。UIは先に作成したReactベースのサンプルを参照します。

---

## 🌐 コンセプト

* 音声＋テキストを入力 → 話者ごとに分離（話者分離）
* 各話者の各セグメントについて、感情・アクセント・音量・テンポ・方言・語彙など複数の特徴を抽出
* 特徴の抽出手法を複数候補から選択可能（例：ピッチ抽出をPraat/pyWORLD/J-ToBIから選択）
* 結果をチャート・テキスト・ハイライトなどで表示し、比較・分析を容易にする

---

## 🎛️ 主な機能

### 入力と処理

1. **音声アップロード**：ファイル選択で入力
2. **話者分離（Diarization）**：pyannote.audioやNeMoなどで話者区間を抽出
3. **文字起こし（ASR）**：WhisperXなどでテキスト化
4. **特徴抽出（選択可能）**：

   * **感情**：wav2vec2、くしなだ、Fusionモデル
   * **アクセント/ピッチ**：Praat、pyWORLD、J-ToBIルール
   * **音量**：RMS、LUFS、A-weighted
   * **テンポ**：ASR文字数/秒、モーラ数、VAD比率
   * **方言**：Lexicon TF-IDF、LLM+RAG、音声韻律特徴
   * **語彙（品位/語感）**：形態素辞書、文体レベル、Valence語感辞書

### 表示

* **タイムラインビュー**：話者ごとの発話区間を色分け
* **感情グラフ**：喜怒哀楽スコアを積み上げエリアで表示
* **ピッチカーブ**：アクセント傾向をラインチャートで表示
* **音量・テンポバー**：発話ごとの強弱・速度
* **方言スコア積み上げ**：地域ごとの寄与度を可視化
* **語彙ハイライト**：特徴語・方言語・敬語などを強調表示

---

## 🧠 目的

* **可視化重視**：音声データを「見て理解できる」形に。
* **説明可能性**：モデル出力の根拠（どの発話・どの語が寄与したか）を示す。
* **柔軟性**：抽出手段を複数持ち、改良・差し替えが容易。

---

## 🏗️ 想定アーキテクチャ

```
音声入力
  ↓
話者分離（pyannote / NeMo）
  ↓
文字起こし（WhisperX）
  ↓
特徴抽出
  ├ 感情（wav2vec2 / くしなだ）
  ├ ピッチ・音量（Praat, pyWORLD, torchaudio）
  ├ 方言（TF-IDF / LLM+RAG）
  └ 語彙（辞書 / 文体解析）
  ↓
JSONフォーマット統合
  ↓
フロント表示（React / Tailwind / Recharts）
```

---

## 🧵 バッチ処理（分析用データ準備モード）

UIを使わず、コマンドラインで**大量の音声を一括処理**して、可視化UIが読めるJSON/Parquetを吐き出せます。

* **入力**：`data/audio/*.wav` などのディレクトリ
* **処理**：話者分離 → ASR → 特徴抽出（選択手法はフラグで指定）
* **出力**：

  * `segments.jsonl`（1行=1セグメント：id, start, end, speaker, text, features...）
  * `speakers.parquet`（話者集約統計：発話比率、平均テンポ、感情平均など）
* **例（擬似コマンド）**：

  ```bash
  python batch/run_pipeline.py \
    --in data/audio \
    --out data/processed \
    --emotion ser_w2v \
    --pitch praat \
    --loudness lufs \
    --tempo asr_chars \
    --dialect lexicon_tfidf \
    --lexicon pos_dict
  ```
* **UI連携**：UIは `segments.jsonl` を読み込み、同じ見た目で再生（インポート機能）

---

## 🔐 データ倫理

* 個人情報・声紋情報は匿名化（話者ID付与）
* 発話内容にPIIが含まれる場合は部分マスク
* 分析結果は「傾向値」であり確定的判断ではない旨を明示

---

## 📈 今後の拡張

* **音声＋テキスト連動型RAG**（説明文生成・方言解釈）
* **アクセント・イントネーションの音符風可視化**
* **Big Fiveや感情傾向との関連分析**
* **複数話者比較モード（相互影響分析）**

---

次ステップでは、`DETAILS & TASKS` ドキュメントにて、

* 各モジュールの詳細仕様
* データ構造定義
* 実装タスクと優先度
  を整理していきます。
